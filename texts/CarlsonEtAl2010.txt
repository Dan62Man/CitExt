AI has a long history of research on autonomous agents,
problem solving, and learning, e.g., SOAR (Laird, Newell,
and Rosenbloom 1987), PRODIGY (Carbonell et al. 1991),
EURISKO (Lenat 1983), ACT-R (Anderson et al. 2004),
and ICARUS (Langley et al. 1991). In comparison, our focus to date has been on semi-supervised learning to read,
with less focus on problem-solving search. Nevertheless,
earlier work provides a variety of design principles upon
which we have drawn. For example, the role of the KB in
our approach is similar to the role of the “blackboard” in
early systems for speech recognition (Erman et al. 1980),
and the frame-based representation of our KB is a reimplementation of the THEO system (Mitchell et al. 1991) which
was originally designed to support integrated representation,
inference and learning.
There is also previous research on life-long learning, such
as Thrun and Mitchell (1995), which focuses on using previously learned functions (e.g., a robot’s next-state function) to
bias learning of new functions (e.g., the robot’s control function). Banko and Etzioni (2007) consider a lifelong learning
setting where an agent builds a theory of a domain, and explore different strategies for deciding which of many possible learning tasks to tackle next. Although our current system uses a simpler strategy of training all functions on each
iteration, choosing what to learn next is an important capability for lifelong learning.
Our approach employs semi-supervised bootstrap learning methods, which begin with a small set of labeled data,
train a model, then use that model to label more data.
Yarowsky (1995) uses bootstrap learning to train classifiers
for word sense disambiguation. Bootstrap learning has also
been employed successfully in many applications, including web page classification (Blum and Mitchell 1998), and
named entity classification (Collins and Singer 1999).
Bootstrap learning approaches can often suffer from “semantic drift,” where labeling errors in the learning process
can accumulate (Riloff and Jones 1999; Curran, Murphy,
and Scholz 2007). There is evidence that constraining the
learning process helps to mitigate this issue. For example,
if classes are mutually exclusive, they can provide negative
examples for each other (Yangarber 2003). Relation arguments can also be type-checked to ensure that they match
expected types (Pas¸ca et al. 2006). Carlson et al. (2010)
employ such strategies and use multiple extraction methods,
which are required to agree. Carlson et al. refer to the idea
of adding many constraints between functions being learned
as “coupled semi-supervised learning.” Chang, Ratinov, and
Roth (2007) also showed that enforcing constraints given as
domain knowledge can improve semi-supervised learning.
Pennacchiotti and Pantel (2009) present a framework
for combining the outputs of an ensemble of extraction
methods, which they call “Ensemble Semantics.” Multiple extraction systems provide candidate category instances,
which are then ranked using a learned function that uses
features from many different sources (e.g., query logs,
Wikipedia). Their approach uses a more sophisticated ranking method than ours, but is not iterative. Thus, their ideas
are complementary to our work, as we could use their ranking method as part of our general approach.
Other previous work has demonstrated that pattern-based
and list-based extraction methods can be combined in a synergistic fashion to achieve significant improvements in recall (Etzioni et al. 2004). Downey, Etzioni, and Soderland (2005) presented a probabilistic model for using and
training multiple extractors where the extractors (in their
work, different extraction patterns) make uncorrelated errors. It would be interesting to apply a similar probabilistic
model to cover the setting in this paper, where there are multiple extraction methods which themselves employ multiple
extractors (e.g., textual patterns, wrappers, rules).
Nahm and Mooney (2000) first demonstrated that inference rules could be mined from beliefs extracted from text.
Our work can also be seen as an example of multi-task
learning in which several different functions are trained together, as in (Caruana 1997; Yang, Kim, and Xing 2009), in
order to improve learning accuracy. Our approach involves
a kind of multi-task learning of multiple types of functions
— 531 functions in total in the experiments reported here
— in which different methods learn different functions with
overlapping inputs and outputs, and where constraints provided by the ontology (e.g., ‘athlete’ is a subset of ‘person’,
and mutually exclusive with ‘city’) support accurate semisupervised learning of the entire ensemble of functions.
