Typically, Information Extraction (IE) systems learn
an extractor for each target relation from labeled training examples (Kim and Moldovan, 1993;
Riloff, 1996; Soderland, 1999). This approach to IE
does not scale to corpora where the number of target
relations is very large, or where the target relations
cannot be specified in advance. Open IE solves this
problem by identifying relation phrases—phrases
that denote relations in English sentences (Banko
et al., 2007). The automatic identification of relation phrases enables the extraction of arbitrary relations from sentences, obviating the restriction to a
pre-specified vocabulary.
Open IE systems have achieved a notable measure
of success on massive, open-domain corpora drawn
from the Web, Wikipedia, and elsewhere. (Banko et
al., 2007; Wu and Weld, 2010; Zhu et al., 2009). The
output of Open IE systems has been used to support
tasks like learning selectional preferences (Ritter et
al., 2010), acquiring common sense knowledge (Lin
et al., 2010), and recognizing entailment (Schoenmackers et al., 2010; Berant et al., 2011). In addition, Open IE extractions have been mapped onto
existing ontologies (Soderland et al., 2010).
We have observed that two types of errors are frequent in the output of Open IE systems such as TEXTRUNNER and WOE: incoherent extractions and uninformative extractions.
Incoherent extractions are cases where the extracted relation phrase has no meaningful interpretation (see Table 1 for examples). Incoherent extractions arise because the learned extractor makes a
sequence of decisions about whether to include each
word in the relation phrase, often resulting in incomprehensible predictions. To solve this problem, we
introduce a syntactic constraint: every multi-word
relation phrase must begin with a verb, end with a
preposition, and be a contiguous sequence of words
in the sentence. Thus, the identification of a relation
phrase is made in one fell swoop instead of on the
basis of multiple, word-by-word decisions.
Uninformative extractions are extractions that
omit critical information. For example, consider the
sentence “Faust made a deal with the devil.” Previous Open IE systems return the uninformative
(Faust, made, a deal)
instead of
(Faust, made a deal with, the devil).
This type of error is caused by improper handling
of relation phrases that are expressed by a combination of a verb with a noun, such as light verb
constructions (LVCs). An LVC is a multi-word expression composed of a verb and a noun, with the
noun carrying the semantic content of the predicate (Grefenstette and Teufel, 1995; Stevenson et al.,
2004; Allerton, 2002). Table 2 illustrates the wide
range of relations expressed this way, which are not
captured by existing open extractors. Our syntactic
constraint leads the extractor to include nouns in the
relation phrase, solving this problem.
Although the syntactic constraint significantly reduces incoherent and uninformative extractions, it
allows overly-specific relation phrases such as is offering only modest greenhouse gas reduction targets
at. To avoid overly-specific relation phrases, we introduce an intuitive lexical constraint: a binary relation phrase ought to appear with at least a minimal
number of distinct argument pairs in a large corpus.
In summary, this paper articulates two simple but
surprisingly powerful constraints on how binary relationships are expressed via verbs in English sentences, and implements them in the REVERB Open
IE system. We release REVERB and the data used in
our experiments to the research community.
The rest of the paper is organized as follows. Section 2 analyzes previous work. Section 3 defines our
constraints precisely. Section 4 describes REVERB,
our implementation of the constraints. Section 5 reports on our experimental results. Section 6 concludes with a summary and discussion of future
work.
Open IE systems like TEXTRUNNER (Banko et al.,
2007), WOEpos, and WOEparse (Wu and Weld, 2010)
focus on extracting binary relations of the form
(arg1, relation phrase, arg2) from text. These systems all use the following three-step method:
1. Label: Sentences are automatically labeled
with extractions using heuristics or distant supervision.
2. Learn: A relation phrase extractor is learned
using a sequence-labeling graphical model
(e.g., CRF).
3. Extract: the system takes a sentence as input, identifies a candidate pair of NP arguments
(arg1, arg2) from the sentence, and then uses
the learned extractor to label each word between the two arguments as part of the relation
phrase or not.
The extractor is applied to the successive sentences
in the corpus, and the resulting extractions are collected.
This method faces several challenges. First,
the training phase requires a large number of labeled training examples (e.g., 200, 000 heuristicallylabeled sentences for TEXTRUNNER and 300, 000
for WOE). Heuristic labeling of examples obviates
hand labeling but results in noisy labels and distorts
the distribution of examples. Second, the extraction step is posed as a sequence-labeling problem,
where each word is assigned its own label. Because
each assignment is uncertain, the likelihood that the
extracted relation phrase is flawed increases with
the length of the sequence. Finally, the extractor
chooses an extraction’s arguments heuristically, and
cannot backtrack over this choice. This is problematic when a word that belongs in the relation phrase
is chosen as an argument (for example, deal from
the “made a deal with” sentence).
Because of the feature sets utilized in previous
work, the learned extractors ignore both “holistic”
aspects of the relation phrase (e.g., is it contiguous?)
as well as lexical aspects (e.g., how many instances
of this relation are there?). Thus, as we show in Section 5, systems such as TEXTRUNNER are unable
to learn the constraints embedded in REVERB. Of
course, a learning system, utilizing a different hypothesis space, and an appropriate set of training examples, could potentially learn and refine the constraints in REVERB. This is a topic for future work,
which we consider in Section 6.
The first Open IE system was TEXTRUNNER
(Banko et al., 2007), which used a Naive Bayes
model with unlexicalized POS and NP-chunk features, trained using examples heuristically generated
from the Penn Treebank. Subsequent work showed
that utilizing a linear-chain CRF (Banko and Etzioni, 2008) or Markov Logic Network (Zhu et al.,
2009) can lead to improved extraction. The WOE
systems introduced by Wu and Weld make use of
Wikipedia as a source of training data for their extractors, which leads to further improvements over
TEXTRUNNER (Wu and Weld, 2010). Wu and Weld
also show that dependency parse features result in a
dramatic increase in precision and recall over shallow linguistic features, but at the cost of extraction
speed.
Other approaches to large-scale IE have included
Preemptive IE (Shinyama and Sekine, 2006), OnDemand IE (Sekine, 2006), and weak supervision
for IE (Mintz et al., 2009; Hoffmann et al., 2010).
Preemptive IE and On-Demand IE avoid relationspecific extractors, but rely on document and entity clustering, which is too costly for Web-scale IE.
Weakly supervised methods use an existing ontology to generate training data for learning relationspecific extractors. While this allows for learning relation-specific extractors at a larger scale than
what was previously possible, the extractions are
still restricted to a specific ontology.
Many systems have used syntactic patterns based
on verbs to extract relation phrases, usually relying on a full dependency parse of the input sentence
(Lin and Pantel, 2001; Stevenson, 2004; Specia and
Motta, 2006; Kathrin Eichler and Neumann, 2008).
Our work differs from these approaches by focusing on relation phrase patterns expressed in terms
of POS tags and NP chunks, instead of full parse
trees. Banko and Etzioni (Banko and Etzioni, 2008)
showed that a small set of POS-tag patterns cover a
large fraction of relationships in English, but never
incorporated the patterns into an extractor. This paper reports on a substantially improved model of binary relation phrases, which increases the recall of
the Banko-Etzioni model (see Section 3.3). Further,
while previous work in Open IE has mainly focused
on syntactic patterns for relation extraction, we introduce a lexical constraint that boosts precision and
recall.
Finally, Open IE is closely related to semantic role
labeling (SRL) (Punyakanok et al., 2008; Toutanova
et al., 2008) in that both tasks extract relations and
arguments from sentences. However, SRL systems
traditionally rely on syntactic parsers, which makes
them susceptible to parser errors and substantially
slower than Open IE systems such as REVERB. This
difference is particularly important when operating
on the Web corpus due to its size and heterogeneity.
Finally, SRL requires hand-constructed semantic resources like Propbank and Framenet (Martha and
Palmer, 2002; Baker et al., 1998) as input. In contrast, Open IE systems require no relation-specific
training data. ReVerb, in particular, relies on its explicit lexical and syntactic constraints, which have
no correlate in SRL systems. For a more detailed
comparison of SRL and Open IE, see (Christensen
et al., 2010).