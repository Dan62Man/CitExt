Most Information Extraction (IE) tasks require
identifying and categorizing phrase spans, some
of which might be nested. For example, entity
recognition involves assigning an entity label to
a phrase span. Relation Extraction (RE) involves
assigning a relation type between pairs of spans.
Coreference resolution groups spans referring to
the same entity into one cluster. Thus, we might
expect that knowledge learned from one task might
benefit another.
Most previous work in IE (e.g., (Nadeau and
Sekine, 2007; Chan and Roth, 2011)) employs a
pipeline approach, first detecting entities and then
using the detected entity spans for relation extraction and coreference resolution. To avoid cascading
errors introduced by pipeline-style systems, recent
work has focused on coupling different IE tasks as
in joint modeling of entities and relations (Miwa
and Bansal, 2016; Zhang et al., 2017), entities and
coreferences (Hajishirzi et al., 2013; Durrett and
Klein, 2014), joint inference (Singh et al., 2013)
or multi-task (entity/relation/coreference) learning (Luan et al., 2018a). These models mostly
rely on the first layer LSTM to share span representations between different tasks and are usually
designed for specific domains.
In this paper, we introduce a general framework
Dynamic Graph IE (DYGIE) for coupling multiple
information extraction tasks through shared span
representations which are refined leveraging contextualized information from relations and coreferences. Our framework is effective in several domains, demonstrating a benefit from incorporating
broader context learned from relation and coreference annotations.
Figure 1 shows an example illustrating the potential benefits of entity, relation, and coreference
contexts. It is impossible to predict the entity labels for This thing and it from within-sentence context alone. However, the antecedent car strongly
suggests that these two entities have a VEH type.
Similarly, the fact that Tom is located at Starbucks
and Mike has a relation to Tom provides support for
the fact that Mike is located at Starbucks.
DYGIE uses multi-task learning to identify entities, relations, and coreferences through shared
span representations using dynamically constructed
span graphs. The nodes in the graph are dynamically selected from a beam of highly-confident
mentions, and the edges are weighted according
to the confidence scores of relation types or coreferences. Unlike the multi-task method that only
shares span representations from the local context (Luan et al., 2018a), our framework leverages
rich contextual span representations by propagating information through coreference and relation
links. Unlike previous BIO-based entity recognition systems (Collobert and Weston, 2008; Lample
et al., 2016; Ma and Hovy, 2016) that assign a text
span to at most one entity, our framework enumerates and represents all possible spans to recognize
arbitrarily overlapping entities.
We evaluate DYGIE on several datasets spanning many domains (including news, scientific articles, and wet lab experimental protocols), achieving state-of-the-art performance across all tasks and
domains and demonstrating the value of coupling
related tasks to learn richer span representations.
For example, DYGIE achieves relative improvements of 5.7% and 9.9% over state of the art on the
ACE05 entity and relation extraction tasks, and an
11.3% relative improvement on the ACE05 overlapping entity extraction task.
The contributions of this paper are threefold.
1) We introduce the dynamic span graph framework as a method to propagate global contextual
information, making the code publicly available.
2) We demonstrate that our framework significantly
outperforms the state-of-the-art on joint entity and
relation detection tasks across four datasets: ACE
2004, ACE 2005, SciERC and the Wet Lab Protocol Corpus. 3) We further show that our approach
excels at detecting entities with overlapping spans,
achieving an improvement of up to 8 F1 points on
three benchmarks annotated with overlapped spans:
ACE 2004, ACE 2005 and GENIA.
Previous studies have explored joint modeling (Miwa and Bansal, 2016; Zhang et al., 2017;
Singh et al., 2013; Yang and Mitchell, 2016)) and
multi-task learning (Peng and Dredze, 2015; Peng
et al., 2017; Luan et al., 2018a, 2017a) as methods
to share representational strength across related information extraction tasks. The most similar to
ours is the work in Luan et al. (2018a) that takes
a multi-task learning approach to entity, relation,
and coreference extraction. In this model, the different tasks share span representations that only
incorporate broader context indirectly via the gradients passed back to the LSTM layer. In contrast,
DYGIE uses dynamic graph propagation to explicitly incorporate rich contextual information into the
span representations.
Entity recognition has commonly been cast as
a sequence labeling problem, and has benefited
substantially from the use of neural architectures
(Collobert et al., 2011; Lample et al., 2016; Ma and
Hovy, 2016; Luan et al., 2017b, 2018b). However,
most systems based on sequence labeling suffer
from an inability to extract entities with overlapping spans. Recently Katiyar and Cardie (2018)
and Wang and Lu (2018) have presented methods
enabling neural models to extract overlapping entities, applying hypergraph-based representations on
top of sequence labeling systems. Our framework
offers an alternative approach, forgoing sequence
labeling entirely and simply considering all possible spans as candidate entities.
Neural graph-based models have achieved significant improvements over traditional featurebased approaches on several graph modeling tasks.
Knowledge graph completion (Yang et al., 2015;
Bordes et al., 2013) is one prominent example.
For relation extraction tasks, graphs have been
used primarily as a means to incorporate pipelined
features such as syntactic or discourse relations
(Peng et al., 2017; Song et al., 2018; Zhang et al.,
2018). Christopoulou et al. (2018) models all possible paths between entities as a graph, and refines
pair-wise embeddings by performing a walk on the
graph structure. All these previous works assume
that the nodes of the graph (i.e. the entity candidates to be considered during relation extraction)
are predefined and fixed throughout the learning
process. On the other hand, our framework does
not require a fixed set of entity boundaries as an
input for graph construction. Motivated by state-ofthe-art span-based approaches to coreference resolution (Lee et al., 2017, 2018) and semantic role
labeling (He et al., 2018), the model uses a beam
pruning strategy to dynamically select high-quality
spans, and constructs a graph using the selected
spans as nodes.
Many state-of-the-art RE models rely upon domain-specific external syntactic tools to construct dependency paths between the entities in
a sentence (Li and Ji, 2014; Xu et al., 2015; Miwa
and Bansal, 2016; Zhang et al., 2017). These systems suffer from cascading errors from these tools
and are hard to generalize to different domains.
To make the model more general, we combine
the multitask learning framework with ELMo embeddings (Peters et al., 2018) without relying on
external syntactic tools and risking the cascading
errors that accompany them, and improve the interaction between tasks through dynamic graph propagation. While the performance of DyGIE benefits
from ELMo, it advances over some systems (Luan
et al., 2018a; Sanh et al., 2019) that also incorporate
ELMo. The analyses presented here give insights
into the benefits of joint modeling.