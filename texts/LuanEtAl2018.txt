As scientific communities grow and evolve, new
tasks, methods, and datasets are introduced and
different methods are compared with each other.
Despite advances in search engines, it is still hard
to identify new technologies and their relationships
with what existed before. To help researchers more
quickly identify opportunities for new combinations of tasks, methods and data, it is important to
design intelligent algorithms that can extract and
organize scientific information from a large collection of documents.
Organizing scientific information into structured
knowledge bases requires information extraction
(IE) about scientific entities and their relationships.
However, the challenges associated with scientific
IE are greater than for a general domain. First, annotation of scientific text requires domain expertise
which makes annotation costly and limits resources.
In addition, most relation extraction systems are designed for within-sentence relations. However, extracting information from scientific articles requires
extracting relations across sentences. Figure 1 illustrates this problem. The cross-sentence relations
between some entities can only be connected by
entities that refer to the same scientific concept,
including generic terms (such as the pronoun it,
or phrases like our method) that are not informative by themselves. With co-reference, context-free
grammar can be connected to MORPA through the
intermediate co-referred pronoun it. Applying existing IE systems to this data, without co-reference,
will result in much lower relation coverage (and a
sparse knowledge base).
In this paper, we develop a unified learning
model for extracting scientific entities, relations,
and coreference resolution. This is different from
previous work (Luan et al., 2017b; Gupta and Manning, 2011; Tsai et al., 2013; Gabor et al. ´ , 2018)
which often addresses these tasks as independent
components of a pipeline. Our unified model is
a multi-task setup that shares parameters across
low-level tasks, making predictions by leveraging
context across the document through coreference
links. Specifically, we extend prior work for learning span representations and coreference resolution
(Lee et al., 2017; He et al., 2018). Different from a
standard tagging system, our system enumerates all
possible spans during decoding and can effectively
detect overlapped spans. It avoids cascading errors
between tasks by jointly modeling all spans and
span-span relations.
To explore this problem, we create a dataset SCIERC for scientific information extraction, which
includes annotations of scientific terms, relation
categories and co-reference links. Our experiments
show that the unified model is better at predicting span boundaries, and it outperforms previous
state-of-the-art scientific IE systems on entity and
relation extraction (Luan et al., 2017b; Augenstein
et al., 2017). In addition, we build a scientific
knowledge graph integrating terms and relations
extracted from each article. Human evaluation
shows that propagating coreference can significantly improve the quality of the automatic constructed knowledge graph.
In summary we make the following contributions. We create a dataset for scientific information
extraction by jointly annotating scientific entities,
relations, and coreference links. Extending a previous end-to-end coreference resolution system, we
develop a multi-task learning framework that can
detect scientific entities, relations, and coreference
clusters without hand-engineered features. We use
our unified framework to build a scientific knowledge graph from a large collection of documents
and analyze information in scientific literature.
There has been growing interest in research on automatic methods for information extraction from
scientific articles. Past research in scientific IE
addressed analyzing citations (Athar and Teufel,
2012b,a; Kas, 2011; Gabor et al., 2016; Sim et al.,
2012; Do et al., 2013; Jaidka et al., 2014; AbuJbara and Radev, 2011), analyzing research community (Vogel and Jurafsky, 2012; Anderson et al.,
2012), and unsupervised methods for extracting scientific entities and relations (Gupta and Manning,
2011; Tsai et al., 2013; Gabor et al. , 2016).
More recently, two datasets in SemEval 2017
and 2018 have been introduced, which facilitate
research on supervised and semi-supervised learning for scientific information extraction. SemEval
17 (Augenstein et al., 2017) includes 500 paragraphs from articles in the domains of computer
science, physics, and material science. It includes
three types of entities (called keyphrases): Tasks,
Methods, and Materials and two relation types:
hyponym-of and synonym-of. SemEval 18 (Gabor ´
et al., 2018) is focused on predicting relations between entities within a sentence. It consists of six
relation types. Using these datasets, neural models (Ammar et al., 2017, 2018; Luan et al., 2017b;
Augenstein and Søgaard, 2017) are introduced for
extracting scientific information. We extend these
datasets by increasing relation coverage, adding
cross-sentence coreference linking, and removing
some annotation constraints. Different from most
previous IE systems for scientific literature and general domains (Miwa and Bansal, 2016; Xu et al.,
2016; Peng et al., 2017; Quirk and Poon, 2017;
Luan et al., 2018; Adel and Schutze ¨ , 2017), which
use preprocessed syntactic, discourse or coreference features as input, our unified framework does
not rely on any pipeline processing and is able to
model overlapping spans.
While Singh et al. (2013) show improvements
by jointly modeling entities, relations, and coreference links, most recent neural models for these
tasks focus on single tasks (Clark and Manning,
2016; Wiseman et al., 2016; Lee et al., 2017; Lample et al., 2016; Peng et al., 2017) or joint entity
and relation extraction (Katiyar and Cardie, 2017;
Zhang et al., 2017; Adel and Schutze ¨ , 2017; Zheng
et al., 2017). Among those studies, many papers assume the entity boundaries are given, such as (Clark
and Manning, 2016), Adel and Schutze ¨ (2017) and
Peng et al. (2017). Our work relaxes this constraint
and predicts entity boundaries by optimizing over
all possible spans. Our model draws from recent
end-to-end span-based models for coreference resolution (Lee et al., 2017, 2018) and semantic role
labeling (He et al., 2018) and extends them for the
multi-task framework involving the three tasks of
identification of entity, relation and coreference.
Neural multi-task learning has been applied to
a range of NLP tasks. Most of these models share
word-level representations (Collobert and Weston,
2008; Klerke et al., 2016; Luan et al., 2016, 2017a;
Rei, 2017), while Peng et al. (2017) uses high-order
cross-task factors. Our model instead propagates
cross-task information via span representations,
which is related to Swayamdipta et al. (2017).